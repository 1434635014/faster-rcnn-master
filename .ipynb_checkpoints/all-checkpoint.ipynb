{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import voc_data\n",
    "import importlib\n",
    "import config\n",
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import proposal_func\n",
    "import detection_target_fixed\n",
    "import classifier_fixed\n",
    "import utils\n",
    "\n",
    "importlib.reload(voc_data)\n",
    "importlib.reload(config)\n",
    "importlib.reload(proposal_func)\n",
    "importlib.reload(detection_target_fixed)\n",
    "importlib.reload(classifier_fixed)\n",
    "importlib.reload(utils)\n",
    "\n",
    "classes_num = len(voc_data.classes_arr)\n",
    "config = config.Config()\n",
    "fpn_classifiler = classifier_fixed.fpn_classifiler\n",
    "anchor_num = len(config.scales) * len(config.ratios) # 一个锚点对应的anchor数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super(self.__class__, self).call(inputs, training=False)\n",
    "\n",
    "# ResNet网络 的building_block\n",
    "# filter：卷积核的通道数\n",
    "# block：block的标识\n",
    "def building_block(filters, block):\n",
    "    if block != 0:\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    \n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4 * filters, (1,1))(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        \n",
    "        if block == 0:\n",
    "            # 保证shorcut的filters和上面y的filters个数一致\n",
    "            shorcut = KL.Conv2D(4 * filters, (1,1), strides=stride)(x)\n",
    "            shorcut = BatchNorm(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "\n",
    "        # 结合两个支路的输出\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f\n",
    "\n",
    "# ResNet网络\n",
    "def resNet_featureExtractor(inputs):\n",
    "    filters = 64   # 第一个卷积核的通道数\n",
    "    x = KL.Conv2D(filters, (2,2), strides=2)(inputs)\n",
    "    x = BatchNorm(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    # resnet50\n",
    "    blocks = [3, 4, 6]    # buildblock的数量  change\n",
    "    \n",
    "    for i, block_num in enumerate(blocks):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters = filters * 2\n",
    "    return x\n",
    "\n",
    "def rpn_net(inputs, k):\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    rpn_class = KL.Conv2D(2 * k, (1,1))(shared_map)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    # 分类的得分\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    # 边框的得分\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0], -1, 4]))(y)\n",
    "    \n",
    "    return rpn_class, rpn_prob, rpn_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 160, 160, 64) 832         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_310 (BatchNorm)      (None, 160, 160, 64) 256         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 160, 160, 64) 0           batch_norm_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 80, 80, 64)   4160        activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_311 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 80, 80, 64)   0           batch_norm_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 80, 80, 64)   36928       activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_312 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 80, 80, 64)   0           batch_norm_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 80, 80, 256)  16640       activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 80, 80, 256)  16640       activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_313 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_314 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 80, 80, 256)  0           batch_norm_313[0][0]             \n",
      "                                                                 batch_norm_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 80, 80, 256)  0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 80, 80, 64)   16448       activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_315 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 80, 80, 64)   0           batch_norm_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 80, 80, 64)   36928       activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_316 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 80, 80, 64)   0           batch_norm_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 80, 80, 256)  16640       activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_317 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 80, 80, 256)  0           batch_norm_317[0][0]             \n",
      "                                                                 activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 80, 80, 256)  0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 80, 80, 64)   16448       activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_318 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 80, 80, 64)   0           batch_norm_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 80, 80, 64)   36928       activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_319 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 80, 80, 64)   0           batch_norm_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 80, 80, 256)  16640       activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_320 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 80, 80, 256)  0           batch_norm_320[0][0]             \n",
      "                                                                 activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 80, 80, 256)  0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 40, 40, 128)  32896       activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_321 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 40, 40, 128)  0           batch_norm_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 40, 40, 128)  147584      activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_322 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 40, 40, 128)  0           batch_norm_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 40, 40, 512)  66048       activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 40, 40, 512)  131584      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_323 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_324 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 40, 40, 512)  0           batch_norm_323[0][0]             \n",
      "                                                                 batch_norm_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 40, 40, 512)  0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 40, 40, 128)  65664       activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_325 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 40, 40, 128)  0           batch_norm_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 40, 40, 128)  147584      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_326 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 40, 40, 128)  0           batch_norm_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 40, 40, 512)  66048       activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_327 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 40, 40, 512)  0           batch_norm_327[0][0]             \n",
      "                                                                 activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 40, 40, 512)  0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 40, 40, 128)  65664       activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_328 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 40, 40, 128)  0           batch_norm_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 40, 40, 128)  147584      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_329 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 40, 40, 128)  0           batch_norm_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 40, 40, 512)  66048       activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_330 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 40, 40, 512)  0           batch_norm_330[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 40, 40, 512)  0           add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 40, 40, 128)  65664       activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_331 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 40, 40, 128)  0           batch_norm_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 40, 40, 128)  147584      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_332 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 40, 40, 128)  0           batch_norm_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 40, 40, 512)  66048       activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_333 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 40, 40, 512)  0           batch_norm_333[0][0]             \n",
      "                                                                 activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 40, 40, 512)  0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 20, 20, 256)  131328      activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_334 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 20, 20, 256)  0           batch_norm_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 20, 20, 256)  590080      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_335 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 20, 20, 256)  0           batch_norm_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 20, 20, 1024) 263168      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 20, 20, 1024) 525312      activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_336 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_337 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 20, 20, 1024) 0           batch_norm_336[0][0]             \n",
      "                                                                 batch_norm_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 20, 20, 1024) 0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 20, 20, 256)  262400      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_338 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 20, 20, 256)  0           batch_norm_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 20, 20, 256)  590080      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_339 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 20, 20, 256)  0           batch_norm_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 20, 20, 1024) 263168      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_340 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 20, 20, 1024) 0           batch_norm_340[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 20, 20, 1024) 0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 20, 20, 256)  262400      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_341 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 20, 20, 256)  0           batch_norm_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 20, 20, 256)  590080      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_342 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 20, 20, 256)  0           batch_norm_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 20, 20, 1024) 263168      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_343 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 20, 20, 1024) 0           batch_norm_343[0][0]             \n",
      "                                                                 activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 20, 20, 1024) 0           add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 20, 20, 256)  262400      activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_344 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 20, 20, 256)  0           batch_norm_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 20, 20, 256)  590080      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_345 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 20, 20, 256)  0           batch_norm_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 20, 20, 1024) 263168      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_346 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 20, 20, 1024) 0           batch_norm_346[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 20, 20, 1024) 0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 20, 20, 256)  262400      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_347 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 20, 20, 256)  0           batch_norm_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 20, 20, 256)  590080      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_348 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 20, 20, 256)  0           batch_norm_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 20, 20, 1024) 263168      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_349 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 20, 20, 1024) 0           batch_norm_349[0][0]             \n",
      "                                                                 activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 20, 20, 1024) 0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 20, 20, 256)  262400      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_350 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 20, 20, 256)  0           batch_norm_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 20, 20, 256)  590080      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_351 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 20, 20, 256)  0           batch_norm_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 20, 20, 1024) 263168      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_352 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 20, 20, 1024) 0           batch_norm_352[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 20, 20, 1024) 0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 20, 20, 256)  2359552     activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 20, 20, 256)  0           conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 20, 20, 18)   4626        activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, None, 2)      0           conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 20, 20, 36)   9252        activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, None, 2)      0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 20, 20, 36)   0           conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, None, 2)      0           activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, None, 4)      0           activation_364[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 10,953,974\n",
      "Trainable params: 10,923,382\n",
      "Non-trainable params: 30,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = KL.Input((config.image_size[0], config.image_size[0], 3))  # change\n",
    "fp = resNet_featureExtractor(x)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(fp, anchor_num)\n",
    "model = Model([x], [rpn_class, rpn_prob, rpn_bbox])\n",
    "model.summary()\n",
    "# plot_model(model, to_file=\"model/model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x：rpn_box，counts：anchor为1的个数，num_rows = len(counts)：总共多少个\n",
    "# 小函数，取出rpn_box前面有值的“偏移量”\n",
    "def batch_back(x, counts, num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "# 分类loss\n",
    "# rpn_match：真实下标  rpn_class_logits：实际计算出的结果\n",
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    # 压缩最后一维，变成一维的坐标，rpn_match (None, 576, 1) => (None, 576) \n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    # 取出 -1 和 1 的坐标\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))\n",
    "    # 把 -1 和 0 变成 0， 1 还是 1\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)\n",
    "    # 取出实际计算出的所有-1 和 1坐标的anchor\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)     ### prediction\n",
    "    # 取出真实下标的所有-1 和 1坐标的anchor => 现在是（0, 1）0：表示背景 1：表示前景\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   ### target\n",
    "    # 计算loss\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class, output=rpn_class_logits, from_logits=True)\n",
    "    # 计算平均，如果loss算出东西了，就取平均，如果没算出东西，就取0\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "# 回归loss\n",
    "# target_bbox：真实的边框, rpn_match：真实的anchor下标, rpn_bbox：实际计算出来的结果边框\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    # 压缩最后一维，变成一维的坐标，rpn_match (None, 576, 1) => (None, 576) \n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    # 取出 1 的坐标\n",
    "    indices = tf.where(K.equal(rpn_match, 1))\n",
    "    # 取出所有 1 的“偏移量”\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    # 得出为 1 的“偏移量”的个数\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1)\n",
    "    # 取出 target_bbox 中为1的“偏移量”\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, config.batch_size)\n",
    "    # 求误差\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    # 取出小于1的部分\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    # 小于1的部分给抛物线  diff**2\n",
    "    # 大于1的部分给直线（不会对大的误差敏感） diff-0.5\n",
    "    loss = (less_than_one * 0.5 * diff**2) + ((1 - less_than_one) * (diff - 0.5))\n",
    "    # 计算平均，如果loss算出东西了，就取平均，如果没算出东西，就取0\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "# 置信度loss\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    return loss\n",
    "\n",
    "# 回归loss\n",
    "def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):\n",
    "\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    target_bbox = K.reshape(target_bbox, (-1, 4))\n",
    "    pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))\n",
    "\n",
    "    positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "    positive_roi_class_ids = tf.cast(\n",
    "        tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "    indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "    target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "    pred_bbox = tf.gather_nd(pred_bbox, indices)\n",
    "\n",
    "    loss = K.switch(tf.size(target_bbox) > 0,\n",
    "                    smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    loss = K.reshape(loss, [1, 1])\n",
    "    return loss\n",
    "\n",
    "# 分类loss\n",
    "def mrcnn_class_loss_graph(target_class_ids, pred_class_logits, active_class_ids):\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "    # Find predictions of classes that are not in the dataset.\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    # TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "    #       images in a batch have the same active_class_ids\n",
    "    pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    pred_active = tf.cast(pred_active, tf.float32)\n",
    "    loss = loss * pred_active\n",
    "\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss\n",
    "\n",
    "# 分类loss  v2版本\n",
    "def mrcnn_class_loss_graphV2(target_class_ids, pred_class_logits, active_class_ids, batch_size=config.batch_size):\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    #pred_active = tf.zeros((batch_size, tf.shape(target_class_ids)[1]))\n",
    "    pred_active = utils.batch_slice([active_class_ids, pred_class_ids], lambda x,y:tf.gather(x,y), batch_size)\n",
    "    #for i in range(batch_size):\n",
    "    #    pred_active[i] = tf.gather(active_class_ids[i], pred_class_ids[i])\n",
    "        #pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "    pred_active = tf.cast(pred_active, tf.float32)\n",
    "    loss = loss * pred_active\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一个修正层，用于使用模型时\n",
    "import keras.engine as KE\n",
    "\n",
    "def refine_detections(rois, probs, deltas):\n",
    "    argMax_probs = tf.argmax(probs, axis=1)\n",
    "    max_probs = tf.reduce_max(probs, axis=1)\n",
    "    keep_idxs = tf.where(max_probs > 0.5)[:,0]\n",
    "    idx_y = tf.cast(np.arange(16), tf.int32)\n",
    "    idx_x = tf.cast(argMax_probs, tf.int32)\n",
    "    idxs = tf.stack([idx_y, idx_x],axis=1)\n",
    "    deltas_keep = tf.gather_nd(deltas, idxs)\n",
    "    refined_rois = proposal_func.anchor_refinement(tf.cast(rois, tf.float32),\n",
    "                                 tf.cast(deltas_keep * config.RPN_BBOX_STD_DEV, tf.float32))\n",
    "    rois_ready = tf.gather(refined_rois, keep_idxs)\n",
    "    class_ids = tf.gather(argMax_probs, keep_idxs)\n",
    "    class_ids = tf.to_float(class_ids)[..., tf.newaxis]\n",
    "    detections = tf.concat([rois_ready, class_ids], axis=1)\n",
    "    gap = tf.maximum(16 - tf.shape(detections)[0],0)\n",
    "    detections = tf.pad(detections, [(0, gap), (0, 0)], \"CONSTANT\")\n",
    "    return detections\n",
    "\n",
    "class DetectionLayer(KE.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DetectionLayer, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        rois = inputs[0]\n",
    "        probs = inputs[1]\n",
    "        deltas = inputs[2]\n",
    "        \n",
    "        detections_batch = utils.batch_slice(\n",
    "            [rois, probs, deltas],\n",
    "            lambda x, y, z: refine_detections(x, y, z),\n",
    "            config.batch_size)\n",
    "        #return tf.reshape(\n",
    "        #    detections_batch,\n",
    "        #    [16, 8, -1])\n",
    "        return detections_batch\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 8, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training inference \n",
    "\n",
    "## RPN   all \n",
    "class fasterRCNN():\n",
    "    def __init__(self, mode, subnet, config):\n",
    "        assert mode in [\"training\", \"inference\"]\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.subnet = subnet\n",
    "        self.keras_model = self.build(mode=mode, subnet=subnet, config=config)\n",
    "    \n",
    "    def build(self, mode, subnet, config):\n",
    "        \n",
    "        assert mode in [\"training\", \"inference\"]\n",
    "        # 图片的输入\n",
    "        input_image = KL.Input(shape=[config.image_size[0], config.image_size[1], 3], dtype=tf.float32)\n",
    "        # 真实的边框输入\n",
    "        input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)\n",
    "        # 真实的分类输入（21个类别，包含1个背景）\n",
    "        input_class_ids = KL.Input(shape=[None],dtype=tf.int32)\n",
    "        input_active_ids = KL.Input(shape=[classes_num,], dtype=tf.int32)\n",
    "        # 真实的anchor分类 -1,0,1输入\n",
    "        input_rpn_match = KL.Input(shape=[None, 1], dtype=tf.int32)\n",
    "        # 真实的anchor偏移量输入\n",
    "        input_rpn_bbox = KL.Input(shape=[None, 4], dtype=tf.float32)\n",
    "        # 图片宽高\n",
    "        h, w = config.image_size[: 2]\n",
    "        # 图片宽高比例\n",
    "        image_scale = K.cast(K.stack([h,w,h,w], axis=0), tf.float32)\n",
    "        gt_bboxes = KL.Lambda(lambda x: x / image_scale)(input_bboxes)\n",
    "        \n",
    "        # 创建模型\n",
    "        feature_map = resNet_featureExtractor(input_image)\n",
    "        rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, anchor_num)\n",
    "        # proposals层（PS：这里改了下参数）\n",
    "        proposals = proposal_func.proposal(proposal_count=16, nms_thresh=0.7, anchors=voc_data._anchors, batch_size=config.batch_size, config=config)([rpn_prob, rpn_bbox])\n",
    "        \n",
    "        # 训练模式\n",
    "        if mode == \"training\":\n",
    "            target_rois, target_class_ids, target_delta, target_bboxes = detection_target_fixed.DetectionTarget(config=config, \\\n",
    "                              name=\"proposal_target\")([proposals,input_class_ids,gt_bboxes])\n",
    "            \n",
    "            denomrlaize_rois = KL.Lambda(lambda x: 8.0*x, name=\"denormalized_rois\")(target_rois)\n",
    "            loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")([input_rpn_match, rpn_class])\n",
    "            loss_rpn_bbox = KL.Lambda(lambda x: rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")([input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "\n",
    "            # rpn模式\n",
    "            if subnet == \"rpn\":\n",
    "                model = Model([input_image, input_bboxes, input_class_ids, input_active_ids, input_rpn_match, input_rpn_bbox],\n",
    "                              [feature_map, rpn_class, rpn_prob, rpn_bbox, proposals, target_rois, denomrlaize_rois, target_class_ids, \\\n",
    "                               target_delta, target_bboxes, loss_rpn_match, loss_rpn_bbox])\n",
    "            # rpn+fpn模式\n",
    "            elif subnet == \"all\":\n",
    "                mrcnn_class_logits, mrcnn_class, mrcnn_bbox = fpn_classifiler(feature_map, denomrlaize_rois, config.batch_size, 21, 7, classes_num)\n",
    "                bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=\"bbox_loss\")(\n",
    "                                                [target_delta, target_class_ids, mrcnn_bbox])\n",
    "                class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graphV2(*x), name=\"mrcnn_class_loss\")(\n",
    "                                        [target_class_ids, mrcnn_class_logits, input_active_ids])\n",
    "                \n",
    "                model = Model([input_image, input_bboxes, input_class_ids, input_active_ids, input_rpn_match, input_rpn_bbox],\n",
    "                [feature_map, rpn_class, rpn_prob, rpn_bbox, proposals, target_rois, denomrlaize_rois,target_class_ids, target_delta, \\\n",
    "                 target_bboxes, mrcnn_class_logits, mrcnn_class, mrcnn_bbox, loss_rpn_match, loss_rpn_bbox, bbox_loss, class_loss])\n",
    "                model.summary()\n",
    "        # 验证模式\n",
    "        if mode == \"inference\":\n",
    "            denomrlaize_proposals = KL.Lambda(lambda x:8.0*x, name=\"denormalized_proposals\")(proposals)\n",
    "            mrcnn_class_logits, mrcnn_class, mrcnn_bbox = fpn_classifiler(feature_map, denomrlaize_proposals, config.batch_size, 21, 7, classes_num)\n",
    "            detections = DetectionLayer()([proposals, mrcnn_class, mrcnn_bbox])\n",
    "            # 验证模式只传入图片，结果是检测出的框\n",
    "            model = Model([input_image],[detections])\n",
    "            \n",
    "        return model\n",
    "           \n",
    "    # 编译\n",
    "    def compile_(self):\n",
    "        # 添加loss层\n",
    "        loss_lay1 = self.keras_model.get_layer(\"loss_rpn_match\").output\n",
    "        loss_lay2 = self.keras_model.get_layer(\"loss_rpn_bbox\").output\n",
    "        if self.subnet == \"all\":\n",
    "            loss_lay3 = self.keras_model.get_layer(\"bbox_loss\").output\n",
    "            loss_lay4 = self.keras_model.get_layer(\"mrcnn_class_loss\").output\n",
    "\n",
    "        self.keras_model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "        self.keras_model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "        if self.subnet == \"all\":\n",
    "            self.keras_model.add_loss(tf.reduce_mean(loss_lay3))\n",
    "            self.keras_model.add_loss(tf.reduce_mean(loss_lay4))\n",
    "\n",
    "        self.keras_model.compile(loss=[None]*len(self.keras_model.output), optimizer=keras.optimizers.SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False))\n",
    "        \n",
    "        # 打印出两个loss的收敛情况\n",
    "        self.keras_model.metrics_names.append(\"loss_rpn_match\")\n",
    "        self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keep_dims=True))\n",
    "        self.keras_model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "        self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keep_dims=True))\n",
    "\n",
    "        # 打印出两个loss的收敛情况\n",
    "        if self.subnet == \"all\":\n",
    "            self.keras_model.metrics_names.append(\"bbox_loss\")\n",
    "            self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay3, keep_dims=True))\n",
    "            self.keras_model.metrics_names.append(\"mrcnn_class_loss\")\n",
    "            self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay4, keep_dims=True))\n",
    "    \n",
    "    # 训练方法\n",
    "    def training(self, dataGen):\n",
    "        self.compile_()\n",
    "        def step_decay(epoch):\n",
    "            initial_lrate = 0.0001\n",
    "            drop = 0.8\n",
    "            epochs_drop = 5.0\n",
    "            lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "            print('学习率：' + str(lrate))\n",
    "            return lrate\n",
    "        lrate = LearningRateScheduler(step_decay)\n",
    "        his = self.keras_model.fit_generator(dataGen, steps_per_epoch=20, epochs=20, callbacks=[lrate]) \n",
    "    \n",
    "    # 验证方法\n",
    "    def inference(self, testdata):\n",
    "        assert self.mode == \"inference\"\n",
    "        out = self.keras_model.predict(testdata)\n",
    "        return out\n",
    "    \n",
    "    # 保存权重参数\n",
    "    def save_weights(self, weights_path):\n",
    "        self.keras_model.save_weights(weights_path)\n",
    "        \n",
    "    # 加载权重参数\n",
    "    def load_weights(self, weights_path):\n",
    "        from keras.engine import topology\n",
    "        import h5py\n",
    "        f = h5py.File(weights_path)\n",
    "        layers = self.keras_model.layers\n",
    "        topology.load_weights_from_hdf5_group_by_name(f, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc\n",
    "def data_Gen(num_batch, batch_size, config, beginIndex):\n",
    "    print(\"----------------\")\n",
    "    index = beginIndex\n",
    "    for iii in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        active_ids = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, active_id, rpn_match, rpn_bbox, idxLen, anchors = voc_data.getAllImage(index)\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "            active_ids.append(active_id)\n",
    "            index += 1\n",
    "            # 数据下标大于16000，重置为0\n",
    "            if index >= 16000:\n",
    "                index = 0\n",
    "\n",
    "        print(\"数据：\" + str(index))\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        active_ids = np.concatenate(active_ids, 0).reshape(batch_size, -1 )\n",
    "        yield [images, bboxes, class_ids, active_ids, rpn_matchs, rpn_bboxes],[]\n",
    "\n",
    "# 开始下标\n",
    "beginIndex = 0\n",
    "dataGen = data_Gen(200000, config.batch_size, config, beginIndex) # 10000个数据，batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 160, 160, 64) 832         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_353 (BatchNorm)      (None, 160, 160, 64) 256         conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 160, 160, 64) 0           batch_norm_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 80, 80, 64)   4160        activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_354 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 80, 80, 64)   0           batch_norm_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 80, 80, 64)   36928       activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_355 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 80, 80, 64)   0           batch_norm_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 80, 80, 256)  16640       activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 80, 80, 256)  16640       activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_356 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_357 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 80, 80, 256)  0           batch_norm_356[0][0]             \n",
      "                                                                 batch_norm_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 80, 80, 256)  0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 80, 80, 64)   16448       activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_358 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 80, 80, 64)   0           batch_norm_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 80, 80, 64)   36928       activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_359 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 80, 80, 64)   0           batch_norm_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 80, 80, 256)  16640       activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_360 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 80, 80, 256)  0           batch_norm_360[0][0]             \n",
      "                                                                 activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 80, 80, 256)  0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 80, 80, 64)   16448       activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_361 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 80, 80, 64)   0           batch_norm_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 80, 80, 64)   36928       activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_362 (BatchNorm)      (None, 80, 80, 64)   256         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 80, 80, 64)   0           batch_norm_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 80, 80, 256)  16640       activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_363 (BatchNorm)      (None, 80, 80, 256)  1024        conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 80, 80, 256)  0           batch_norm_363[0][0]             \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 80, 80, 256)  0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 40, 40, 128)  32896       activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_364 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 40, 40, 128)  0           batch_norm_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 40, 40, 128)  147584      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_365 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 40, 40, 128)  0           batch_norm_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 40, 40, 512)  66048       activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 40, 40, 512)  131584      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_366 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_367 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 40, 40, 512)  0           batch_norm_366[0][0]             \n",
      "                                                                 batch_norm_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 40, 40, 512)  0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 40, 40, 128)  65664       activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_368 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 40, 40, 128)  0           batch_norm_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 40, 40, 128)  147584      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_369 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 40, 40, 128)  0           batch_norm_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 40, 40, 512)  66048       activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_370 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 40, 40, 512)  0           batch_norm_370[0][0]             \n",
      "                                                                 activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 40, 40, 512)  0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 40, 40, 128)  65664       activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_371 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 40, 40, 128)  0           batch_norm_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 40, 40, 128)  147584      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_372 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 40, 40, 128)  0           batch_norm_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 40, 40, 512)  66048       activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_373 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 40, 40, 512)  0           batch_norm_373[0][0]             \n",
      "                                                                 activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 40, 40, 512)  0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 40, 40, 128)  65664       activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_374 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 40, 40, 128)  0           batch_norm_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 40, 40, 128)  147584      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_375 (BatchNorm)      (None, 40, 40, 128)  512         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 40, 40, 128)  0           batch_norm_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 40, 40, 512)  66048       activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_376 (BatchNorm)      (None, 40, 40, 512)  2048        conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 40, 40, 512)  0           batch_norm_376[0][0]             \n",
      "                                                                 activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 40, 40, 512)  0           add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 20, 20, 256)  131328      activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_377 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 20, 20, 256)  0           batch_norm_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 20, 20, 256)  590080      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_378 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 20, 20, 256)  0           batch_norm_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 20, 20, 1024) 263168      activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 20, 20, 1024) 525312      activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_379 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_380 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 20, 20, 1024) 0           batch_norm_379[0][0]             \n",
      "                                                                 batch_norm_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 20, 20, 1024) 0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 20, 20, 256)  262400      activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_381 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 20, 20, 256)  0           batch_norm_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 20, 20, 256)  590080      activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_382 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 20, 20, 256)  0           batch_norm_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 20, 20, 1024) 263168      activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_383 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 20, 20, 1024) 0           batch_norm_383[0][0]             \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 20, 20, 1024) 0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 20, 20, 256)  262400      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_384 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 20, 20, 256)  0           batch_norm_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 20, 20, 256)  590080      activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_385 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 20, 20, 256)  0           batch_norm_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 20, 20, 1024) 263168      activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_386 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 20, 20, 1024) 0           batch_norm_386[0][0]             \n",
      "                                                                 activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 20, 20, 1024) 0           add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 20, 20, 256)  262400      activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_387 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 20, 20, 256)  0           batch_norm_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 20, 20, 256)  590080      activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_388 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 20, 20, 256)  0           batch_norm_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 20, 20, 1024) 263168      activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_389 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 20, 20, 1024) 0           batch_norm_389[0][0]             \n",
      "                                                                 activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 20, 20, 1024) 0           add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 20, 20, 256)  262400      activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_390 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 20, 20, 256)  0           batch_norm_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 20, 20, 256)  590080      activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_391 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 20, 20, 256)  0           batch_norm_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 20, 20, 1024) 263168      activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_392 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 20, 20, 1024) 0           batch_norm_392[0][0]             \n",
      "                                                                 activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 20, 20, 1024) 0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 20, 20, 256)  262400      activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_393 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 20, 20, 256)  0           batch_norm_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 20, 20, 256)  590080      activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_394 (BatchNorm)      (None, 20, 20, 256)  1024        conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 20, 20, 256)  0           batch_norm_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 20, 20, 1024) 263168      activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_395 (BatchNorm)      (None, 20, 20, 1024) 4096        conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 20, 20, 1024) 0           batch_norm_395[0][0]             \n",
      "                                                                 activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 20, 20, 1024) 0           add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 20, 20, 256)  2359552     activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 20, 20, 256)  0           conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 20, 20, 18)   4626        activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, None, 2)      0           conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 20, 20, 36)   9252        activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, None, 2)      0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 20, 20, 36)   0           conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, None, 2)      0           activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, None, 4)      0           activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "proposal_5 (proposal)           (None, 16, 4)        0           activation_407[0][0]             \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, None, 4)      0           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "proposal_target (DetectionTarge [(None, 21, 4), (Non 0           proposal_5[0][0]                 \n",
      "                                                                 input_31[0][0]                   \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "denormalized_rois (Lambda)      (None, 21, 4)        0           proposal_target[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "roi_pooling_conv_v2_5 (RoiPooli (None, 21, 7, 7, 102 0           activation_404[0][0]             \n",
      "                                                                 denormalized_rois[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv1 (TimeDistribu (None, 21, 1, 1, 256 12845312    roi_pooling_conv_v2_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_bn0 (TimeDistrib (None, 21, 1, 1, 256 1024        mrcnn_class_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 21, 1, 1, 256 0           fpn_classifier_bn0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_conv1 (TimeDistr (None, 21, 1, 1, 512 131584      activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_bn1 (TimeDistrib (None, 21, 1, 1, 512 2048        fpn_classifier_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 21, 1, 1, 512 0           fpn_classifier_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_squeeze (Lambda) (None, 21, 512)      0           activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_fc (TimeDistribu (None, 21, 84)       43092       fpn_classifier_squeeze[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_logits (TimeDist (None, 21, 21)       10773       fpn_classifier_squeeze[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fpn_class_deltas (Reshape)      (None, 21, 21, 4)    0           fpn_classifier_fc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 21)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fpn_classifier_prob (TimeDistri (None, 21, 21)       0           fpn_classifier_logits[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "loss_rpn_match (Lambda)         ()                   0           input_33[0][0]                   \n",
      "                                                                 activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss_rpn_bbox (Lambda)          ()                   0           input_34[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bbox_loss (Lambda)              (1, 1)               0           proposal_target[0][2]            \n",
      "                                                                 proposal_target[0][1]            \n",
      "                                                                 fpn_class_deltas[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_loss (Lambda)       ()                   0           proposal_target[0][1]            \n",
      "                                                                 fpn_classifier_logits[0][0]      \n",
      "                                                                 input_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,987,807\n",
      "Trainable params: 23,955,679\n",
      "Non-trainable params: 32,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = fasterRCNN(mode=\"training\", subnet=\"all\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Epoch 1/20\n",
      "\n",
      "学习率：0.0001\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'active_ids' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-02b477fa413a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# drop = 0.6 衰减率调小\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# learning rate schedule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-6890bb44d54e>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, dataGen)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlrate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mlrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mhis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlrate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# 验证方法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2194\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2196\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                 \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    656\u001b[0m                             \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                             \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                             \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-a95715beb00f>\u001b[0m in \u001b[0;36mdata_Gen\u001b[1;34m(num_batch, batch_size, config, beginIndex)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mrpn_matchs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpn_match\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mrpn_bboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpn_bbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mactive_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactive_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# 数据下标大于16000，重置为0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'active_ids' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# face V2版本\n",
    "# 参数1320万 320 × 320  batch_size：15 steps_per_epoch：20  rpn_stride：16  scales：[40, 50, 65, 85, 110, 140, 190, 250]  buildblock：[7,8,7]   文件名：model_320_16_[epochs数]_v3.h5\n",
    "# 第一次20epochs lr=0.0001 batch_size：10  1w数据\n",
    "# drop = 0.6 衰减率调小\n",
    "# learning rate schedule\n",
    "model.training(dataGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model/model_320_16_v2_500.h5\")\n",
    "# model.save_weights(\"model/model_320_16_700.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterRCNN(mode=\"inference\", subnet=\"rpn\", config=config)\n",
    "model.load_weights(\"model/model_320_16_v2_500.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(dataGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.inference(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "ix = random.sample(range(config.batch_size), 1)[0]\n",
    "\n",
    "image = test_data[0][0][ix]\n",
    "\n",
    "boxes_result = out[ix][:,:4] * config.image_size[0]\n",
    "id_result = out[ix][:,4]\n",
    "\n",
    "plt.imshow(image)\n",
    "Axs = plt.gca()\n",
    "\n",
    "pos_idxs = np.where(id_result > 0)[0]\n",
    "\n",
    "for i in range(pos_idxs.shape[0]):\n",
    "    id_ = pos_idxs[i]\n",
    "    box = boxes_result[id_]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], \n",
    "                           edgecolor=\"r\", facecolor=\"none\")\n",
    "    Axs.add_patch(rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
